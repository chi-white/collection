{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c615395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures  #這用於生成多項式\n",
    "#from cvxopt import matrix, solvers\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss, brier_score_loss\n",
    "from scipy.stats import entropy\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import xgboost\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "#solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f13e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hack(pd_data):\n",
    "    print(\"|\",end=\" \")\n",
    "    for i in pd_data.columns:\n",
    "        print(\"|\", i,end = \" \")\n",
    "    print(\"|\")\n",
    "    for i in range(pd_data.shape[1]+1):\n",
    "        print(\"|---\", end=\" \")\n",
    "    print(\"|\")\n",
    "    for i in range(pd_data.shape[0]):\n",
    "        print(\"|\",pd_data.index[i], end=\" \")\n",
    "        for j in pd_data.iloc[i,:]:\n",
    "            print(\"|\", j, end=\" \")\n",
    "        print(\"|\")\n",
    "        \n",
    "def print_latex(pd_data):\n",
    "    print('\\\\toprule')\n",
    "    for i in pd_data.columns:\n",
    "        print(\"&\", i,end = \" \")\n",
    "    print('\\\\\\\\')\n",
    "    print('\\midrule')\n",
    "    for i in range(pd_data.shape[0]):\n",
    "        print(pd_data.index[i], end=\" \")\n",
    "        for j in pd_data.iloc[i,:]:\n",
    "            print(\"&\", j, end=\" \")\n",
    "        print('\\\\\\\\')\n",
    "    print('\\\\bottomrule')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ceb5ade",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5e09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditreform.csv',index_col=0)\n",
    "\n",
    "data = data.reset_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e20e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_isna = pd.DataFrame(np.where(np.isnan(data[data.columns[data.isnull().sum()>0]]), 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8741c8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR1     25220.481268\n",
      "VAR2     25851.097490\n",
      "VAR3     21648.591273\n",
      "VAR4     33560.517797\n",
      "VAR5      2019.593934\n",
      "VAR6     17997.038634\n",
      "VAR7     23532.717498\n",
      "VAR8     16514.767755\n",
      "VAR9     16679.961610\n",
      "VAR10     3434.665159\n",
      "VAR11    24164.631214\n",
      "VAR12     8392.623169\n",
      "VAR13     5109.099102\n",
      "VAR14    29170.583471\n",
      "VAR15    27215.026701\n",
      "VAR16    23004.687609\n",
      "VAR17    12759.540474\n",
      "VAR18    18774.139304\n",
      "VAR19    18780.128711\n",
      "VAR20    10586.212651\n",
      "VAR21    30554.317896\n",
      "VAR22    36283.952475\n",
      "VAR23    44148.193487\n",
      "VAR24     9683.429944\n",
      "T2          32.136280\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(data.kurtosis())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54939c4c",
   "metadata": {},
   "source": [
    "## Log transformation on three featrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2de0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\king0\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for i in [i for i in range(0,24)]:\n",
    "    data.iloc[:,i] = np.log(data.iloc[:,i] + 1/(10**(-int(format(np.nanmean(data.iloc[:,i]),'.1E')[-3:])+6)))\n",
    "\n",
    "Y = data.iloc[:,-1]\n",
    "X = data.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fabea40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd6a37b9",
   "metadata": {},
   "source": [
    "## Standarization and impute mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82d88a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.mean()) / X.std()\n",
    "\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962072ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([Y, X],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0e1ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 49, 2) :\n",
    "    data.insert(i, str(i),data_isna.iloc[:,[(i/2)-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ca2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\"$y$\",\"$x_{1}$\",\"$x_{2}$\",\"$x_{3}$\",\"$x_{4}$\",\"$x_{5}$\",\"$x_{6}$\",\"$x_{7}$\",\"$x_{8}$\",\"$x_{9}$\",\"$x_{10}$\", \n",
    "                      \"$x_{11}$\", \"$x_{12}$\", \"$x_{13}$\", \"$x_{14}$\", \"$x_{15}$\", \"$x_{16}$\", \"$x_{17}$\", \"$x_{18}$\", \"$x_{19}$\", \"$x_{20}$\", \n",
    "                      \"$x_{21}$\", \"$x_{22}$\", \"$x_{23}$\", \"$x_{24}$\", \"$x_{25}$\", \"$x_{26}$\", \"$x_{27}$\", \"$x_{28}$\", \"$x_{29}$\", \"$x_{30}$\", \n",
    "                      \"$x_{31}$\", \"$x_{32}$\", \"$x_{33}$\", \"$x_{34}$\", \"$x_{35}$\", \"$x_{36}$\", \"$x_{37}$\", \"$x_{38}$\", \"$x_{39}$\", \"$x_{40}$\", \n",
    "                      \"$x_{41}$\", \"$x_{42}$\", \"$x_{43}$\", \"$x_{44}$\", \"$x_{45}$\", \"$x_{46}$\", \"$x_{47}$\", \"$x_{48}$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b51045",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['mean', 'std', 'min', '50%', 'max']\n",
    "summary = data.describe()\n",
    "na = pd.DataFrame(data.isnull().sum()/len(data)*100,columns = ['NA(%)']).T\n",
    "skew = pd.DataFrame(data.skew(),columns=[\"skewness\"]).T\n",
    "kurt = pd.DataFrame(data.kurtosis(),columns=[\"kurtosis\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab3b293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\toprule\n",
      "& mean & std & min & 50% & max & skewness & kurtosis \\\\\n",
      "\\midrule\n",
      "$y$ & 0.0 & 0.2 & 0.0 & 0.0 & 1.0 & 5.8 & 32.1 \\\\\n",
      "$x_{1}$ & -0.0 & 0.9 & -4.1 & 0.1 & 3.2 & -2.6 & 9.2 \\\\\n",
      "$x_{2}$ & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 43.5 & 1892.9 \\\\\n",
      "$x_{3}$ & 0.0 & 0.9 & -3.6 & 0.0 & 3.4 & -2.0 & 6.2 \\\\\n",
      "$x_{4}$ & 0.2 & 0.4 & 0.0 & 0.0 & 1.0 & 1.2 & -0.5 \\\\\n",
      "$x_{5}$ & -0.0 & 1.0 & -5.4 & 0.2 & 4.2 & -1.4 & 4.2 \\\\\n",
      "$x_{6}$ & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 22.2 & 491.6 \\\\\n",
      "$x_{7}$ & 0.0 & 0.9 & -3.9 & 0.0 & 3.6 & -1.4 & 4.0 \\\\\n",
      "$x_{8}$ & 0.1 & 0.3 & 0.0 & 0.0 & 1.0 & 2.6 & 4.8 \\\\\n",
      "$x_{9}$ & 0.0 & 0.9 & -2.3 & 0.0 & 2.8 & -1.2 & 2.1 \\\\\n",
      "$x_{10}$ & 0.2 & 0.4 & 0.0 & 0.0 & 1.0 & 1.2 & -0.6 \\\\\n",
      "$x_{11}$ & -0.0 & 1.0 & -5.9 & 0.1 & 4.3 & -1.2 & 3.6 \\\\\n",
      "$x_{12}$ & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 38.9 & 1513.3 \\\\\n",
      "$x_{13}$ & 0.0 & 1.0 & -4.4 & 0.1 & 3.9 & -1.7 & 5.2 \\\\\n",
      "$x_{14}$ & 0.0 & 0.2 & 0.0 & 0.0 & 1.0 & 6.0 & 34.3 \\\\\n",
      "$x_{15}$ & 0.0 & 0.8 & -3.4 & 0.0 & 3.1 & -1.7 & 6.6 \\\\\n",
      "$x_{16}$ & 0.4 & 0.5 & 0.0 & 0.0 & 1.0 & 0.3 & -1.9 \\\\\n",
      "$x_{17}$ & 0.0 & 1.0 & -3.0 & 0.3 & 2.9 & -1.7 & 3.0 \\\\\n",
      "$x_{18}$ & 0.0 & 0.1 & 0.0 & 0.0 & 1.0 & 16.0 & 254.2 \\\\\n",
      "$x_{19}$ & -0.0 & 0.5 & -4.2 & 0.0 & 3.4 & -2.9 & 29.5 \\\\\n",
      "$x_{20}$ & 0.8 & 0.4 & 0.0 & 1.0 & 1.0 & -1.2 & -0.6 \\\\\n",
      "$x_{21}$ & -0.0 & 1.0 & -4.2 & 0.1 & 3.7 & -2.1 & 6.5 \\\\\n",
      "$x_{22}$ & 0.1 & 0.2 & 0.0 & 0.0 & 1.0 & 4.0 & 14.2 \\\\\n",
      "$x_{23}$ & 0.0 & 1.0 & -4.0 & 0.1 & 3.5 & -1.4 & 3.8 \\\\\n",
      "$x_{24}$ & 0.0 & 0.1 & 0.0 & 0.0 & 1.0 & 11.6 & 131.6 \\\\\n",
      "$x_{25}$ & -0.0 & 1.0 & -1.2 & 0.4 & 2.3 & -0.2 & -1.6 \\\\\n",
      "$x_{26}$ & 0.0 & 0.1 & 0.0 & 0.0 & 1.0 & 7.9 & 59.9 \\\\\n",
      "$x_{27}$ & 0.0 & 0.8 & -4.3 & 0.0 & 3.6 & -2.5 & 10.6 \\\\\n",
      "$x_{28}$ & 0.3 & 0.5 & 0.0 & 0.0 & 1.0 & 0.9 & -1.1 \\\\\n",
      "$x_{29}$ & -0.0 & 0.8 & -4.0 & 0.0 & 3.7 & -2.0 & 8.1 \\\\\n",
      "$x_{30}$ & 0.4 & 0.5 & 0.0 & 0.0 & 1.0 & 0.3 & -1.9 \\\\\n",
      "$x_{31}$ & -0.0 & 0.9 & -4.5 & 0.1 & 3.7 & -2.1 & 8.2 \\\\\n",
      "$x_{32}$ & 0.1 & 0.3 & 0.0 & 0.0 & 1.0 & 2.7 & 5.2 \\\\\n",
      "$x_{33}$ & -0.0 & 0.4 & -1.4 & 0.0 & 2.3 & -1.0 & 4.7 \\\\\n",
      "$x_{34}$ & 0.1 & 0.2 & 0.0 & 0.0 & 1.0 & 3.5 & 10.1 \\\\\n",
      "$x_{35}$ & 0.0 & 0.9 & -4.7 & 0.0 & 3.5 & -2.7 & 12.2 \\\\\n",
      "$x_{36}$ & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 26.4 & 694.2 \\\\\n",
      "$x_{37}$ & 0.0 & 0.9 & -4.7 & 0.0 & 3.5 & -2.7 & 12.2 \\\\\n",
      "$x_{38}$ & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 30.0 & 895.7 \\\\\n",
      "$x_{39}$ & -0.0 & 0.9 & -2.1 & 0.2 & 2.2 & -1.5 & 1.4 \\\\\n",
      "$x_{40}$ & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 38.9 & 1513.3 \\\\\n",
      "$x_{41}$ & 0.0 & 0.6 & -3.0 & 0.0 & 3.4 & -2.7 & 11.8 \\\\\n",
      "$x_{42}$ & 0.3 & 0.4 & 0.0 & 0.0 & 1.0 & 1.0 & -1.0 \\\\\n",
      "$x_{43}$ & 0.0 & 0.7 & -4.0 & 0.0 & 3.7 & -3.0 & 16.7 \\\\\n",
      "$x_{44}$ & 0.1 & 0.3 & 0.0 & 0.0 & 1.0 & 2.5 & 4.2 \\\\\n",
      "$x_{45}$ & -0.0 & 0.7 & -3.3 & 0.0 & 3.3 & -2.7 & 11.5 \\\\\n",
      "$x_{46}$ & 0.1 & 0.3 & 0.0 & 0.0 & 1.0 & 2.9 & 6.2 \\\\\n",
      "$x_{47}$ & -0.0 & 1.0 & -2.2 & 0.1 & 4.7 & -0.5 & 0.5 \\\\\n",
      "$x_{48}$ & 0.1 & 0.3 & 0.0 & 0.0 & 1.0 & 2.9 & 6.4 \\\\\n",
      "\\bottomrule\n"
     ]
    }
   ],
   "source": [
    "print_latex(pd.concat([summary.loc[col], skew, kurt]).round(1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1678a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa = pd.concat([X, data_isna],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "259dcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data, X_test_data, Y_train_data, Y_test_data = train_test_split(Xa, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "911b620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.concat([Xa,Y],axis = 1)\n",
    "a['Target'] = Y.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7369d467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.973699\n",
       "1    0.026301\n",
       "Name: T2, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_data.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bc6bb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.970453\n",
       "1    0.029547\n",
       "Name: T2, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_data.value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2a45c53",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06fef3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_data.to_numpy()\n",
    "Y_train = Y_train_data.to_numpy().flatten()\n",
    "X_test = X_test_data.to_numpy()\n",
    "Y_test = Y_test_data.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb00a358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546688"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p= 0.6\n",
    "entropy([p, 1-p],base = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6937495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_cv3():\n",
    "    grid={\"C\":[10**i for i in range(-3,3)], \"penalty\":[\"l1\",\"l2\"],\"solver\":[\"liblinear\"],\"random_state\":[0]}\n",
    "    logreg = LogisticRegression(C = 1)\n",
    "    logreg_cv = GridSearchCV(estimator = logreg, param_grid = grid, scoring=\"roc_auc\", cv = 3)\n",
    "    return logreg_cv\n",
    "\n",
    "def LR():\n",
    "    logreg = LogisticRegression(C = 1)\n",
    "    return logreg\n",
    "\n",
    "def XGB():\n",
    "    xgb = xgboost.XGBClassifier()\n",
    "    return xgb\n",
    "\n",
    "\n",
    "class cluster_predict():\n",
    "    def __init__(self, n_cluster, c_cluster, model):\n",
    "        self.n_cluster = n_cluster\n",
    "        self.c_cluster = c_cluster\n",
    "        self.model= model\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        self.cluster = KMedoids(n_clusters = self.n_cluster)\n",
    "        if self.c_cluster == \"AC\":\n",
    "            self.cluster.fit(X[:60000])\n",
    "        elif self.c_cluster == \"PC\":\n",
    "            self.cluster.fit(X[np.where(Y == 1)[0]])\n",
    "        else:\n",
    "            raise ValueError(\"Wrong type of c_cluster method is defined.\")\n",
    "        #print(pd.Series(self.cluster.predict(X)).value_counts())\n",
    "    def cross_tab(self, X, Y):\n",
    "        #re_clust = pd.DataFrame([cluter.predict(X_train), Y_train], index = [\"C\", \"Y\"]).T\n",
    "        cross_tab = pd.crosstab(self.cluster.predict(X), Y).to_numpy()\n",
    "        prob_lst = cross_tab[:,1]/np.sum(cross_tab, axis = 1)\n",
    "        return prob_lst\n",
    "    \n",
    "    def entropy(self, X, Y):\n",
    "        #re_clust = pd.DataFrame([cluter.predict(X_train), Y_train], index = [\"C\", \"Y\"]).T\n",
    "        cross_tab = pd.crosstab(self.cluster.predict(X), Y).to_numpy()\n",
    "        en = 0\n",
    "        for i in range(cross_tab.shape[0]):\n",
    "            p = cross_tab[i,1]/np.sum(cross_tab[i,:])\n",
    "            en += (np.sum(cross_tab[i,:])/len(X))*(entropy([p, 1-p],base = 2))\n",
    "        return en\n",
    "    \n",
    "    def predict(self, X_train, Y_train, X_test, Y_test):\n",
    "        lab_tr = self.cluster.predict(X_train)\n",
    "        lab_ts = self.cluster.predict(X_test)\n",
    "\n",
    "        #model = LogisticRegression()\n",
    "        #model.fit(X_train, Y_train)\n",
    "        #re_train = [roc_auc_score(Y_train, model.predict_proba(X_train)[:,1])]\n",
    "        #re_test = [roc_auc_score(Y_test, model.predict_proba(X_test)[:,1])]\n",
    "        re_train = np.zeros(len(Y_train))\n",
    "        re_test = np.zeros(len(Y_test))\n",
    "        for i in range(self.n_cluster):\n",
    "            posi_tr = np.where(lab_tr == i)[0]\n",
    "            posi_ts = np.where(lab_ts == i)[0]\n",
    "            if self.model == \"LR\":\n",
    "                model = LR()\n",
    "            elif self.model == \"XGB\":\n",
    "                model = XGB()\n",
    "            else:\n",
    "                raise ValueError(\"Wrong type of model is defined.\")\n",
    "                \n",
    "            model.fit(X_train[posi_tr], Y_train[posi_tr])\n",
    "            \n",
    "            re_train[posi_tr] = model.predict_proba(X_train[posi_tr])[:,1]\n",
    "            re_test[posi_ts] = model.predict_proba(X_test[posi_ts])[:,1]\n",
    "\n",
    "        return re_train, re_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff002ea5",
   "metadata": {},
   "source": [
    "# Rescalor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06dbcadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\king0\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\king0\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\king0\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "res_time_lst = []\n",
    "res = []\n",
    "tr_lst = []\n",
    "ts_lst = []\n",
    "\n",
    "\n",
    "for p in [1,2,3]:\n",
    "    poly = PolynomialFeatures(p, include_bias=False)\n",
    "    X_poly_train = np.append(poly.fit_transform(X_train[:,:10]), X_train[:,10:],axis=1)\n",
    "    X_poly_test = np.append(poly.fit_transform(X_test[:,:10]), X_test[:,10:],axis=1)\n",
    "\n",
    "\n",
    "    lm = LinearRegression()\n",
    "    time_start = time.time()\n",
    "    lm.fit(X_poly_train, Y_train)\n",
    "    time_end = time.time()\n",
    "    res_time_lst.append(time_end - time_start)\n",
    "    w_lm = lm.coef_\n",
    "    res.append(w_lm)\n",
    "    X_lm_tr = X_poly_train * w_lm\n",
    "    X_lm_ts = X_poly_test * w_lm\n",
    "\n",
    "\n",
    "    #grid_result = LR_cv3().fit(X_train, Y_train)\n",
    "    lr = LogisticRegression()#**grid_result.best_params_)\n",
    "    time_start = time.time()\n",
    "    lr.fit(X_poly_train, Y_train)\n",
    "    time_end = time.time()\n",
    "    res_time_lst.append(time_end - time_start)\n",
    "    w_lr = lr.coef_[0]\n",
    "    res.append(w_lr)\n",
    "    X_lr_tr = X_poly_train * w_lr\n",
    "    X_lr_ts = X_poly_test * w_lr\n",
    "\n",
    "    time_start = time.time()\n",
    "    w_ig =  mutual_info_classif(X_poly_train,Y_train, random_state = 0)\n",
    "    time_end = time.time()\n",
    "    res_time_lst.append(time_end - time_start)\n",
    "    res.append(w_ig)\n",
    "    X_ig_tr = X_poly_train * w_ig\n",
    "    X_ig_ts = X_poly_test * w_ig\n",
    "\n",
    "\n",
    "    tr = [X_poly_train, X_lm_tr, X_lr_tr, X_ig_tr]\n",
    "    ts = [X_poly_test, X_lm_ts, X_lr_ts, X_ig_ts]\n",
    "    tr_lst.append(tr)\n",
    "    ts_lst.append(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9dffd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('rescalor.xlsx') as w:\n",
    "    pd.DataFrame({'REG':res[0], 'LR':res[1], 'IG':res[2]}).T.to_excel(w, 'identity')\n",
    "    pd.DataFrame({'REG':res[3], 'LR':res[4], 'IG':res[5]}).T.to_excel(w, 'quadratic')\n",
    "    pd.DataFrame({'REG':res[6], 'LR':res[7], 'IG':res[8]}).T.to_excel(w, 'cubic')\n",
    "    #w.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25e2821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_std = []\n",
    "for i in range(len(res)):\n",
    "    res_std.append((res[i]-np.mean(res[i]))/np.std(res[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f06ae2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_lst = []\n",
    "for a in ['Identity','Quadratic','Cubic']:\n",
    "    for b in ['REG', 'LR', 'IG']:\n",
    "        res_lst.append(a)\n",
    "        res_lst.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72373c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_f = np.array([])\n",
    "for i in res_std:\n",
    "    res_f = np.append(res_f, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f32009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_var = np.array([])\n",
    "res_n = np.array([])\n",
    "res_poly = np.array([])\n",
    "for i in [12, 67, 287]:\n",
    "    for _ in range(3):\n",
    "        res_var = np.append(res_var, [j for j in range(i)])\n",
    "    for n in ['REG', 'LR', 'IG']:\n",
    "        res_n = np.append(res_n, [n for j in range(i)])\n",
    "res_poly = np.append(res_poly, np.repeat('Identity',36))\n",
    "res_poly = np.append(res_poly, np.repeat('Quadratic',201))\n",
    "res_poly = np.append(res_poly, np.repeat('Cubic',861))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e54d47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REG</th>\n",
       "      <th>LR</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REG</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796982</td>\n",
       "      <td>0.042651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.796982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IG</th>\n",
       "      <td>0.042651</td>\n",
       "      <td>0.085904</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          REG        LR        IG\n",
       "REG  1.000000  0.796982  0.042651\n",
       "LR   0.796982  1.000000  0.085904\n",
       "IG   0.042651  0.085904  1.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'REG':res[0],'LR':res[1],'IG':res[2]}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30515712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REG</th>\n",
       "      <th>LR</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REG</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731562</td>\n",
       "      <td>-0.051923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.731562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.221914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IG</th>\n",
       "      <td>-0.051923</td>\n",
       "      <td>-0.221914</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          REG        LR        IG\n",
       "REG  1.000000  0.731562 -0.051923\n",
       "LR   0.731562  1.000000 -0.221914\n",
       "IG  -0.051923 -0.221914  1.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'REG':res[3],'LR':res[4],'IG':res[5]}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04bb9107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REG</th>\n",
       "      <th>LR</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REG</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.352069</td>\n",
       "      <td>-0.024565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.352069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.173651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IG</th>\n",
       "      <td>-0.024565</td>\n",
       "      <td>-0.173651</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          REG        LR        IG\n",
       "REG  1.000000  0.352069 -0.024565\n",
       "LR   0.352069  1.000000 -0.173651\n",
       "IG  -0.024565 -0.173651  1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'REG':res[6],'LR':res[7],'IG':res[8]}).corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5430244c",
   "metadata": {},
   "source": [
    "# PD and Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt_lst = []\n",
    "\n",
    "k = [i for i in range(1,10)]\n",
    "\n",
    "for t in ['Train', 'Test']:\n",
    "    for a in ['Identity', 'Quadratic', 'Cubic']:\n",
    "        for b in ['All', 'Positive']:\n",
    "            for c in ['EW', 'REG', 'LR', 'IG']:\n",
    "                for d in k:\n",
    "                    clt_lst.append(t)\n",
    "                    clt_lst.append(a)\n",
    "                    clt_lst.append(b)\n",
    "                    clt_lst.append(c)\n",
    "                    clt_lst.append(d)\n",
    "clt_comb = np.array(clt_lst).reshape(-1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76720f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "method = ['AC', 'PC']\n",
    "clt_time = []\n",
    "tr_en = []\n",
    "ts_en = []\n",
    "tr_pd = []\n",
    "ts_pd = []\n",
    "\n",
    "for x_tr, x_ts in zip(tr_lst, ts_lst):\n",
    "    for m in method:\n",
    "        for X_tr, X_ts in zip(x_tr, x_ts):\n",
    "            for i in k:\n",
    "                cp = cluster_predict(n_cluster = i, c_cluster = m, model = \"LR\")\n",
    "                time_start = time.time()\n",
    "                cp.fit(X_tr, Y_train)\n",
    "                time_end = time.time()\n",
    "                if k == 1:\n",
    "                    clt_time.append(0)\n",
    "                else:\n",
    "                    clt_time.append(time_end - time_start)\n",
    "                \n",
    "\n",
    "                tr_en.append(cp.entropy(X_tr, Y_train))\n",
    "                ts_en.append(cp.entropy(X_ts, Y_test))\n",
    "                tr_pd.append(cp.cross_tab(X_tr, Y_train))\n",
    "                ts_pd.append(cp.cross_tab(X_ts, Y_test))\n",
    "                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea116b9e",
   "metadata": {},
   "source": [
    "# Log-likelihood and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3654b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctp_lst = []\n",
    "\n",
    "k = [i for i in range(4,5)] #change\n",
    "\n",
    "for t in ['Train', 'Test']:\n",
    "\n",
    "    for a in ['Identity', 'Quadratic', 'Cubic']:\n",
    "        for b in ['All', 'Positive']:\n",
    "            for c in ['EW', 'REG', 'LR', 'IG']:\n",
    "                for d in k:\n",
    "                    for e in ['LR', 'XGB']:\n",
    "                        ctp_lst.append(t)\n",
    "                        ctp_lst.append(a)\n",
    "                        ctp_lst.append(b)\n",
    "                        ctp_lst.append(c)\n",
    "                        ctp_lst.append(d)\n",
    "                        ctp_lst.append(e)\n",
    "\n",
    "ctp_comb = np.array(ctp_lst).reshape(-1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52e66866",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = ['AC', 'PC']\n",
    "model = ['LR', 'XGB']\n",
    "res_dic = {0:'EW', 1:'REG',2:'LR',3:'IG'}\n",
    "ctp_time = []\n",
    "tr_ll = []\n",
    "ts_ll = []\n",
    "tr_auc = []\n",
    "ts_auc = []\n",
    "tr_bs = []\n",
    "ts_bs = []\n",
    "\n",
    "for x_tr, x_ts in zip(tr_lst, ts_lst):\n",
    "    for cm in method:\n",
    "        for s, (X_tr, X_ts) in enumerate(zip(x_tr, x_ts)):\n",
    "            for i in k:\n",
    "                for m in model:\n",
    "                    cp = cluster_predict(n_cluster =i, c_cluster = cm, model = m)\n",
    "                    cp.fit(X_tr, Y_train)\n",
    "\n",
    "                    time_start = time.time()\n",
    "                    y_pred_tr, y_pred_ts = cp.predict(X_tr,Y_train,X_ts,Y_test)\n",
    "                    time_end = time.time()\n",
    "                    \n",
    "                    pd.DataFrame({'pred':y_pred_tr}).to_csv('Train_'+cm+'_'+res_dic[s]+'_'+str(i)+'_'+m+'.csv')\n",
    "                    pd.DataFrame({'pred':y_pred_ts}).to_csv('Test_'+cm+'_'+res_dic[s]+'_'+str(i)+'_'+m+'.csv')\n",
    "                    \n",
    "                    ctp_time.append(time_end - time_start)\n",
    "                    \n",
    "                    tr_bs.append(brier_score_loss(Y_train, y_pred_tr))\n",
    "                    ts_bs.append(brier_score_loss(Y_test, y_pred_ts))\n",
    "\n",
    "                    tr_auc.append(roc_auc_score(Y_train, y_pred_tr))\n",
    "                    ts_auc.append(roc_auc_score(Y_test, y_pred_ts))\n",
    "\n",
    "                    tr_ll.append(log_loss(Y_train, y_pred_tr))\n",
    "                    ts_ll.append(log_loss(Y_test, y_pred_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466642ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt_col = pd.DataFrame(clt_comb, columns = ['Data', 'Feature', 'Cluster','Rescalor', 'K'])\n",
    "ctp_col = pd.DataFrame(ctp_comb, columns = ['Data', 'Feature', 'Cluster','Rescalor', 'K', 'Model'])\n",
    "clt_col = clt_col[clt_col['Data']=='Train']\n",
    "ctp_col = ctp_col[ctp_col['Data']=='Train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53bdd8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.ExcelWriter('time_output.xlsx') as w:\n",
    "#     pd.concat([pd.DataFrame(np.array(res_lst).reshape(-1,2), columns = ['Feature', 'Rescalor']),pd.DataFrame({'Time':res_time_lst})],axis=1).to_excel(w, 'rescalor')\n",
    "#     pd.concat([clt_col, pd.DataFrame({'Time':clt_time})], axis = 1).to_excel(w, 'cluster')\n",
    "#     pd.concat([ctp_col, pd.DataFrame({'Time':ctp_time})], axis = 1).to_excel(w, 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9b8f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# with open('positive_rate_tr.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     # write the data\n",
    "#     writer.writerow(['Data', 'Feature', 'Cluster','Rescalor', 'K'] + ['PD'+str(i) for i in range(9)])\n",
    "#     for i in range(len(tr_pd)):\n",
    "#         writer.writerow(list(np.append(clt_col.iloc[i,:].to_numpy(), tr_pd[i])))\n",
    "#         #writer.writerows(i)\n",
    "\n",
    "# with open('positive_rate_ts.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     # write the data\n",
    "#     writer.writerow(['Data', 'Feature', 'Cluster','Rescalor', 'K'] + ['PD'+str(i) for i in range(9)])\n",
    "#     for i in range(len(ts_pd)):\n",
    "#         writer.writerow(list(np.append(clt_col.iloc[i,:].to_numpy(), ts_pd[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('output(k=4).xlsx') as w:\n",
    "#     pd.concat([pd.DataFrame(clt_comb, columns = ['Data', 'Feature', 'Cluster','Rescalor', 'K']), pd.DataFrame({'Entropy':np.append(tr_en, ts_en)})],axis = 1).to_excel(w, 'entropy')\n",
    "    pd.concat([pd.DataFrame(ctp_comb, columns = ['Data', 'Feature', 'Cluster','Rescalor', 'K', 'Model']), pd.DataFrame({'LL':np.append(tr_ll, ts_ll), 'AUC':np.append(tr_auc, ts_auc), 'BS':np.append(tr_bs, ts_bs)})],axis = 1).to_excel(w, 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c067e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
